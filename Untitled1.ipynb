{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytextrank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-54a558fbda67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytextrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytextrank'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import csv\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import pytextrank\n",
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import string\n",
    "import os\n",
    "import io\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "\n",
    "english_stops = []\n",
    "\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    \"\"\" Lowercases, takes out punct and stopwords and short strings \"\"\"\n",
    "    return [token.lower() for token in tokens if (token not in string.punctuation) and\n",
    "               \t(token.lower() not in english_stops) and len(token) > 2]\n",
    "\n",
    "def get_stopwords():\n",
    "    enc = 'utf-8'\n",
    "    with open('stopword_file.csv', 'r', encoding = enc) as f:\n",
    "        reader = csv.reader(f)\n",
    "        keywords = list(reader)\n",
    "    english_stops = [i[0] for i in keywords]\n",
    "    #print ( english_stops)\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "def get_cleanTokens(directory):\n",
    "    cleanTokens = []\n",
    "    wordcount = {} \n",
    "    for filename in os.listdir(directory):\n",
    "        text = get_text(\"KeywordDocs/\" + filename)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        cleanTokens.extend(clean_tokens(tokens))\n",
    "    return cleanTokens\n",
    "     \n",
    "def create_freqList(cleanTokens):\n",
    "    for tok in cleanTokens:\n",
    "        if tok not in wordcount:\n",
    "            wordcount[tok] = 1\n",
    "        else:\n",
    "            wordcount[tok] += 1\n",
    "        \n",
    "    sorted_wordCount = OrderedDict(sorted(wordcount.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    write_csv(sorted_wordCount)\n",
    "\n",
    "def write_csv(sorted_wordCount):\n",
    "    enc = 'utf-8'\n",
    "    if not os.path.isfile('frequency.csv'):\n",
    "        with open('frequency.csv', 'w', encoding = enc) as f:\n",
    "            for key in sorted_wordCount.keys():\n",
    "                f.write(\"%s,\\n\"%(key))\n",
    "    else:\n",
    "        with open('frequency.csv', 'a+', encoding = enc) as f:\n",
    "            for key in sorted_wordCount.keys():\n",
    "                f.write(\"%s,\\n\"%(key))\n",
    "\n",
    "\n",
    "def get_text(filename):\n",
    "    fp = open(filename, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "    return data\n",
    "\n",
    "def create_textrank(sample_text):\n",
    "    file_dic = {\"id\" : 0,\"text\" : sample_text}\n",
    "    file_dic = json.dumps(file_dic)\n",
    "    loaded_file_dic = json.loads(file_dic)\n",
    "\n",
    "    with open('test.json', 'w') as outfile:\n",
    "        json.dump(loaded_file_dic, outfile)\n",
    "        path_stage0 = \"test.json\"\n",
    "        path_stage1 = \"o1.json\"\n",
    "\n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(path_stage0)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "            print(pytextrank.pretty_print(graf._asdict()))\n",
    "\n",
    "    path_stage1 = \"o1.json\"\n",
    "    path_stage2 = \"o2.json\"\n",
    "\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "    with open(path_stage2, 'w', encoding='utf-8') as f:\n",
    "        for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(rl._asdict()))\n",
    "            print(pytextrank.pretty_print(rl))\n",
    "        \n",
    "        \n",
    "if _name_ == '_main_':\n",
    "    get_stopwords()\n",
    "    clean_tokens = get_cleanTokens(\"KeywordDocs\")\n",
    "    #create_freqList(clean_tokens)\n",
    "    create_textrank(' '.join(clean_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank\n",
      "Collecting spacy (from pytextrank)\n",
      "  Using cached https://files.pythonhosted.org/packages/50/31/1496f44c12160282a93c6d36eff5527b89dbc0e6389cf1f4aeeb52caecee/spacy-2.0.18-cp37-cp37m-win_amd64.whl\n",
      "Collecting statistics (from pytextrank)\n",
      "Requirement already satisfied: networkx in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from pytextrank) (2.2)\n",
      "Requirement already satisfied: datasketch in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from pytextrank) (1.4.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from pytextrank) (0.10.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (0.9.6)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (0.2.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2.0.2)\n",
      "Collecting thinc<6.13.0,>=6.12.1 (from spacy->pytextrank)\n",
      "  Using cached https://files.pythonhosted.org/packages/cf/a1/80aabceed94fe348f8ff0a14b89bfbdce7478783c4bba481b96787c05375/thinc-6.12.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2.21.0)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2.0.1)\n",
      "Collecting ujson>=1.35 (from spacy->pytextrank)\n",
      "  Using cached https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.15.4)\n",
      "Requirement already satisfied: regex==2018.01.10 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2018.1.10)\n",
      "Requirement already satisfied: docutils>=0.3 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from statistics->pytextrank) (0.14)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from networkx->pytextrank) (4.3.0)\n",
      "Requirement already satisfied: redis>=2.10.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from datasketch->pytextrank) (3.1.0)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy->pytextrank) (0.5.6)\n",
      "Collecting msgpack-numpy<0.4.4 (from thinc<6.13.0,>=6.12.1->spacy->pytextrank)\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy->pytextrank) (1.12.0)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy->pytextrank) (0.9.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy->pytextrank) (4.28.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy->pytextrank) (1.10.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2018.11.29)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\bhavy\\anaconda3\\lib\\site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy->pytextrank) (0.9.0)\n",
      "Building wheels for collected packages: ujson\n",
      "  Building wheel for ujson (setup.py): started\n",
      "  Building wheel for ujson (setup.py): finished with status 'error'\n",
      "  Complete output from command c:\\users\\bhavy\\anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\bhavy\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ix5purrv\\\\ujson\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\bhavy\\AppData\\Local\\Temp\\pip-wheel-lv5fro0d --python-tag cp37:\n",
      "  Warning: 'classifiers' should be a list, got type 'filter'\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'ujson' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for ujson\n",
      "Failed to build ujson\n",
      "Installing collected packages: msgpack-numpy, thinc, ujson, spacy, statistics, pytextrank\n",
      "  Running setup.py install for ujson: started\n",
      "    Running setup.py install for ujson: finished with status 'error'\n",
      "    Complete output from command c:\\users\\bhavy\\anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\bhavy\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ix5purrv\\\\ujson\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\bhavy\\AppData\\Local\\Temp\\pip-record-_jcvtu5l\\install-record.txt --single-version-externally-managed --compile:\n",
      "    Warning: 'classifiers' should be a list, got type 'filter'\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    building 'ujson' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for ujson\n",
      "Command \"c:\\users\\bhavy\\anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\bhavy\\\\AppData\\\\Local\\\\Temp\\\\pip-install-ix5purrv\\\\ujson\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\bhavy\\AppData\\Local\\Temp\\pip-record-_jcvtu5l\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\bhavy\\AppData\\Local\\Temp\\pip-install-ix5purrv\\ujson\\\n"
     ]
    }
   ],
   "source": [
    "! pip install pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
